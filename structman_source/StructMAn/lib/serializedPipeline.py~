import pymysql as MySQLdb
import os
import sys
import getopt
import time
import multiprocessing
import subprocess
import shutil
import traceback
import math
import json

import pdbParser as pdb
import templateSelection
import templateFiltering
import globalAlignment
import database
import uniprot
import blast
import annovar
import MMseqs2
import sdsc


def SQLDateTime():
    return time.strftime('%Y-%m-%d %H:%M:%S',time.localtime())

def sequenceScan(config,proteins):
    pdb_path = config.pdb_path
    db_adress = config.db_adress
    db_user_name = config.db_user_name
    db_password = config.db_password

    sequenceScanProteins = {}
    sequenceScanPDB = {}
    for u_ac in proteins:
        uni_pos,tags = proteins[u_ac].popNone()
        
        if u_ac.count(':') > 0:
            sequenceScanPDB[u_ac] = tags #PDB inputs are always processed by the sequence scan
        elif uni_pos:
            sequenceScanProteins[u_ac] = tags

    try:
        db = MySQLdb.connect(db_adress,db_user_name,db_password,config.mapping_db)
        cursor = db.cursor()
    except:
        db = None
        cursor = None

    if len(sequenceScanProteins) > 0:
        print("Amount of proteins going into sequenceScan: ",len(sequenceScanProteins))

        gene_sequence_map = uniprot.getSequencesPlain(sequenceScanProteins.keys(),db,cursor,debug=config.verbose)
        for u_ac in gene_sequence_map:
            if gene_sequence_map[u_ac][0] == 1 or gene_sequence_map[u_ac][0] == 0:
                print("Error in sequenceScan with gene: ",u_ac)
                continue
            seq,disorder_scores,disorder_regions_datastruct = gene_sequence_map[u_ac]
            proteins[u_ac].sequence = seq
            proteins[u_ac].disorder_scores = disorder_scores
            proteins[u_ac].disorder_regions = disorder_regions_datastruct
            tags = sequenceScanProteins[u_ac]
            for (pos,aa) in enumerate(seq):
                seq_pos = str(pos+1)
                if seq_pos in proteins[u_ac].positions:
                    proteins[u_ac].positions[seq_pos].add_tags(tags)
                else:
                    position = sdsc.Position(pos=seq_pos,wt_aa=aa,tags=tags)
                    proteins[u_ac].positions[seq_pos] = position

    if len(sequenceScanPDB) > 0:
        pdb_sequence_map,pdb_pos_map = pdb.getSequences(sequenceScanPDB.keys(),pdb_path)
        for u_ac in pdb_sequence_map:
            proteins[u_ac].sequence = pdb_sequence_map[u_ac][0]
            tags = sequenceScanPDB[u_ac]

            residue_id_backmap = {}
            res_pos_map = pdb_pos_map[u_ac]
            for res_id in res_pos_map:
                residue_id_backmap[res_pos_map[res_id]] = res_id

            for (pos,aa) in enumerate(pdb_sequence_map[u_ac][0]):
                seq_pos = str(pos+1)
                res_id = residue_id_backmap[seq_pos]
                if res_id in proteins[u_ac].positions:
                    proteins[u_ac].positions[res_id].pos = seq_pos
                    if tags == None:
                        continue
                    proteins[u_ac].positions[res_id].add_tags(tags)
                else:
                    if tags == None:
                        continue
                    position = sdsc.PDB_Position(pos=seq_pos,pdb_res_nr=res_id,wt_aa=aa,tags=tags)
                    proteins[u_ac].positions[res_id] = position


    if db != None:
        db.close()
    return proteins

def buildQueue(config,db,cursor,filename,junksize,mrna_fasta=None):
    db_adress = config.db_adress
    db_user_name = config.db_user_name
    db_password = config.db_password

    verbose = config.verbose

    t0 =time.time()

    proteins = {}
    u_ids = set()
    u_acs = set()
    nps = set()
    id_map = {}
    ac_map = {}
    np_map = {}

    pdb_map = {}

    f = open(filename, "r")
    lines = f.read().split('\n')
    f.close()
    ac_id_map = {}
    tag_map = {}
    fasta_map = {}

    for line in lines:
        if line == '':
            continue
        if len(line) < 3:
            print("Skipped input line:\n%s\nToo short.\n" % line)
            continue
        line = line.replace(' ','\t')
        words = line.split("\t")
        if len(words) < 1:
            print("Skipped input line:\n%s\nToo few words.\n" % line)
            continue
        sp_id = words[0]#.replace("'","\\'")

        tags = set()

        if len(words) > 2:
            tags = set(words[2].split(','))

        try:
            if len(words) == 1 or words[1] == '':
                if not sp_id.count(':') == 1: #this means sp_id is not a pdb-id
                    position = sdsc.Position(tags=tags)
                else:
                    position = sdsc.PDB_Position(tags=tags)
            else:

                aachange = words[1].replace("\n","")
                if not sp_id.count(':') == 1: #this means sp_id is not a pdb-id

                    if ord(aachange[0]) > 47 and ord(aachange[0]) < 58: #if first char is a number
                        aa1 = 'X'
                        aachange = "X%s" % aachange
                    else:
                        aa1 = aachange[0]


                    if ord(aachange[-1]) > 47 and ord(aachange[-1]) < 58: #if last char is a number

                        pos = aachange[1:]


                        position = sdsc.Position(pos=pos,wt_aa=aa1,tags=tags)
                    else:
                        aa2 = aachange.split(',')[0][-1]
                        pos = int(aachange.split(',')[0][1:-1])

                        position = sdsc.Position(pos=pos,wt_aa=aa1,mut_aas = set(aa2),tags=tags)

                else: #this means sp_id is a pdb-id
                    if aachange.count('_') == 1: #This means a mutant amino acid type is given
                        aachange = aachange.replace('_','')
                        position = sdsc.PDB_Position(pdb_res_nr=aachange[1:-1],wt_aa=aachange[0],mut_aas = set(aachange[-1]),tags=tags)
                    else:
                        position = sdsc.PDB_Position(pdb_res_nr=aachange[1:],wt_aa=aachange[0],tags=tags)

        except:
            print("File Format Error: ",line)
            sys.exit()

        if mrna_fasta == None:

            if sp_id[2] == "_":
                nps.add(sp_id)
                if not sp_id in np_map:
                    np_map[sp_id] = [position]
                else:
                    np_map[sp_id].append(position)
                
            else:
                if sp_id.count('_') > 0:
                    u_ids.add(sp_id)
                    if not sp_id in id_map:
                        id_map[sp_id] = [position]
                    else:
                        id_map[sp_id].append(position)
                elif len(sp_id) == 6 and sp_id.count(':') == 1:
                    pdb_chain_tuple = '%s:%s' % (sp_id[:4].upper(),sp_id[-1]) #enforce uppercase pdb-id 
                    if not pdb_chain_tuple in pdb_map:
                        pdb_map[pdb_chain_tuple] = [position]
                    else:
                        pdb_map[pdb_chain_tuple].append(position)
                else:
                    u_acs.add(sp_id)
                    if not sp_id in ac_map:
                        ac_map[sp_id] = [position]
                    else:
                        ac_map[sp_id].append(position)
        else:
            #fasta input needs an update
            """
            if species != 'multi':
                sp_id = '%s_%s' % (sp_id,species)
            if not sp_id in genes:
                genes[sp_id] = set([aachange])
            else:
                genes[sp_id].add(aachange)

            if not species in fasta_map:
                if species == 'multi':
                    fasta_map[species] = '%s/%s.fa' % (mrna_fasta,species)
                else:
                    fasta_map[species] = mrna_fasta
            """

    t1 = time.time()
    if verbose:
        print("buildQueue Part 1: ",str(t1-t0))

    try:
        db_uniprot = MySQLdb.connect(db_adress,db_user_name,db_password,config.mapping_db)
        cursor_uniprot = db_uniprot.cursor()
    except:
        db_uniprot = None
        cursor_uniprot = None

    proteins = uniprot.IdMapping(ac_map,id_map,np_map,db_uniprot,cursor_uniprot,pdb_map,verbose=verbose)

    if db_uniprot != None:
        db_uniprot.close()

    t2 = time.time()
    if verbose:
        print("buildQueue Part 2: ",str(t2-t1))

    proteins = sequenceScan(config,proteins)

    t3 = time.time()
    if verbose:
        print("buildQueue Part 3: ",str(t3-t2))

    t4 = time.time()
    if verbose:
        print("buildQueue Part 4: ",str(t4-t3))


    outlist = []

    s = len(proteins)
    print("Total proteins: ",s)

    if s > junksize:

        n_of_batches = s//junksize
        if s%junksize != 0:
            n_of_batches += 1
        batchsize = s//n_of_batches
        rest = s%n_of_batches
        outlist = []

        for i in range(0,n_of_batches):
            new_map = {}
            if i == n_of_batches - 1: # the last batch
                batchsize += rest
            for j in range(0,batchsize):
                (key,value) = proteins.popitem()
                new_map[key] = value
            outlist.append(new_map)
        new_map = {}
        while len(proteins) > 0:
            (key,value) = proteins.popitem()
            new_map[key] = value
        if len(new_map) > 0:
            outlist.append(new_map)
    else:
        outlist.append(proteins)

    t5 = time.time()
    if verbose:
        print("buildQueue Part 5: ",str(t5-t4))

    return outlist

def nToAA(seq):
    table={ 
    'TTT': 'F', 'TTC': 'F', 'TTA': 'L', 'TTG': 'L', 'TCT': 'S', 
    'TCC': 'S', 'TCA': 'S', 'TCG': 'S', 'TAT': 'Y', 'TAC': 'Y', 
    'TGT': 'C', 'TGC': 'C', 'TGG': 'W', 'CTT': 'L', 'CTC': 'L', 
    'CTA': 'L', 'CTG': 'L', 'CCT': 'P', 'CCC': 'P', 'CCA': 'P', 
    'CCG': 'P', 'CAT': 'H', 'CAC': 'H', 'CAA': 'Q', 'CAG': 'Q', 
    'CGT': 'R', 'CGC': 'R', 'CGA': 'R', 'CGG': 'R', 'ATT': 'I', 
    'ATC': 'I', 'ATA': 'I', 'ATG': 'M', 'ACT': 'T', 'ACC': 'T', 
    'ACA': 'T', 'ACG': 'T', 'AAT': 'N', 'AAC': 'N', 'AAA': 'K', 
    'AAG': 'K', 'AGT': 'S', 'AGC': 'S', 'AGA': 'R', 'AGG': 'R', 
    'GTT': 'V', 'GTC': 'V', 'GTA': 'V', 'GTG': 'V', 'GCT': 'A', 
    'GCC': 'A', 'GCA': 'A', 'GCG': 'A', 'GAT': 'D', 'GAC': 'D', 
    'GAA': 'E', 'GAG': 'E', 'GGT': 'G', 'GGC': 'G', 'GGA': 'G', 
    'GGG': 'G', }
    stop_codons = ('TAG','TGA','TAA')

    i = 1
    triple = ''
    aa_seq = ''
    for char in list(seq):        
        triple += char
        if i%3 == 0:
            if triple in table:
                aa = table[triple]
            elif triple in stop_codons:
                aa = ''
            aa_seq += aa
            triple = ''
        i += 1
    return aa_seq

def getSequences(proteins,config,manager,lock,db,cursor):
    number_of_processes = config.proc_n
    human_id_mapping_path = config.human_id_mapping_path
    pdb_path = config.pdb_path
    pdb_input_asymetric_unit = config.pdb_input_asymetric_unit
    blast_processes = config.blast_processes
    cwd = os.getcwd()
    verbose = config.verbose

    t0 = time.time()
    try:
        db_uniprot = MySQLdb.connect(config.db_adress,config.db_user_name,config.db_password,config.mapping_db)
        cursor_uniprot = db_uniprot.cursor()
    except:
        db_uniprot = None
        cursor_uniprot = None
    
    
    uniprot.getSequences(proteins,'%s/human_info_map.tab' % human_id_mapping_path,db_uniprot,cursor_uniprot)

    if db_uniprot != None:
        db_uniprot.close()
    t1 = time.time()
    if verbose:
        print("Time for getSequences Part 1: %s" % str(t1-t0))

    #pdb_sequence_map,pdb_pos_map = pdb.getSequences(pdb_dict,pdb_path,AU=pdb_input_asymetric_unit)

    database.addProtInfos(proteins,db,cursor)

    t2 = time.time()
    if verbose:
        print("Time for getSequences Part 2: %s" % str(t2-t1))

    background_iu_process = None
    if config.iupred_path != '':
        iupred_path = config.iupred_path
        if iupred_path.count('mobidb-lite') > 0:
            mobi_lite = True
        else:
            mobi_lite = False

        t0 = time.time()

        if not mobi_lite:
            in_queue = manager.Queue()
            out_queue = manager.Queue()
        else:
            mobi_list = []

        stored_disorder_ids = []
        for u_ac in proteins.protein_map:
            seq = proteins[u_ac].sequence
            if seq == 0 or seq == 1 or seq == None:
                continue
            disorder_scores = proteins[u_ac].disorder_scores
            disorder_regions = proteins[u_ac].disorder_regions
            if disorder_scores == None:
                if not mobi_lite:
                    in_queue.put((u_ac,seq))
                else:
                    mobi_list.append('>%s\n%s\n' % (u_ac,seq))
            elif disorder_scores != 'Stored':
                disorder_scores_datastruct = {}
                for pos,score in enumerate(disorder_scores):
                    seq_pos = pos + 1
                    if pos >= len(seq):
                        if verbose:
                            print('Warning: illegal position ',pos,' for sequence of ',u_ac)
                        continue
                    disorder_scores_datastruct[seq_pos] = (seq[pos],score)
                proteins[u_ac].disorder_scores = disorder_scores_datastruct
                proteins[u_ac].disorder_regions = disorder_regions
                proteins[u_ac].disorder_tool = 'MobiDB3.0'

        if not mobi_lite:
            processes = {}
            for i in range(1,blast_processes + 1):
                try:
                    os.stat("%s/%d" %(cwd,i))
                except:
                    os.mkdir("%s/%d" %(cwd,i))
                p = multiprocessing.Process(target=paraIupred, args=(config,in_queue,out_queue,lock))
                processes[i] = p
                p.start()
            for i in processes:
                processes[i].join()

            out_queue.put(None)
            while True:
                out = out_queue.get()
                if out == None:
                    break
                iupred_parts = out
                proteins[iupred_parts[0]].disorder_scores = iupred_parts[2]
                proteins[iupred_parts[0]].disorder_regions = iupred_parts[1]
                proteins[iupred_parts[0]].disorder_tool = 'IUpred'

        else:
            mobi_tmp_file = 'mobi_tmp_file.fasta'
            f = open(mobi_tmp_file,'w')
            f.write(''.join(mobi_list))
            f.close()
            mobi_bin_path = '%s/binx/' % iupred_path.rsplit('/',1)[0]
            mobi_threads = min([7,config.proc_n])
            p = subprocess.Popen([iupred_path,mobi_tmp_file,'-t',str(mobi_threads),'-bin',mobi_bin_path,'-l'],stdout=subprocess.PIPE,stderr=subprocess.PIPE,universal_newlines=True)
            out,err = p.communicate()
            os.remove(mobi_tmp_file)
            if err != '':
                print('Warning: mobidb-lite threw an error: ',err)
            else:
                entries = []
                for line in out.split('}'):
                    if line.count('{') == 0:
                        continue
                    line = line + '}'
                    #print(line)
                    mobi_results = json.loads(line)
                    u_ac = mobi_results['acc']
                    raw_scores = mobi_results['p']
                    raw_regions = mobi_results['regions']
                    regions = []
                    for a,b in raw_regions:
                        regions.append([a,b,'disorder'])
                    scores = {}
                    seq = proteins[u_ac].sequence
                    disorder_scores = proteins[u_ac].disorder_scores
                    disorder_regions = proteins[u_ac].disorder_regions
                    for pos,score in enumerate(raw_scores):
                        scores[str(pos+1)] = (seq[pos],score)
                    proteins[u_ac].disorder_scores = scores
                    proteins[u_ac].disorder_regions = regions
                    proteins[u_ac].disorder_tool = 'mobidb-lite'

        t1 = time.time()
        if verbose:
            print("Time for addIupred Part 1: %s" % str(t1-t0))

        background_iu_process = database.addIupred(proteins,config)

        t2 = time.time()
        if verbose:
            print("Time for addIupred Part 2: %s" % str(t2-t1))

    return background_iu_process

def paraIupred(config,in_queue,out_queue,lock):
    iupred_path = config.iupred_path
    with lock:
        in_queue.put(None)
    while True:
        with lock:
            inp = in_queue.get()
        if inp == None:
            return

        (u_ac,seq) = inp

        #print seq


        p = subprocess.Popen(['python3','%s/iupred2a.py' % iupred_path,seq,'glob'],stdout=subprocess.PIPE,stderr=subprocess.PIPE,universal_newlines=True)
        out,err = p.communicate()
        #print out
        after_glob = False
        iupred_parts = [u_ac,[],{}]
        for line in out.split('\n'):
            if len(line) < 3:
                continue
            if line[0] == '#':
                continue
            if line[0] == '1':
                after_glob = True
            words = line.split()
            if not after_glob:
                if len(words) < 4:
                    continue
                if words[0] == 'globular' and words[1] == 'domain':
                    lower_bound,upper_bound = words[3].split('-')
                    iupred_parts[1].append((int(lower_bound),int(upper_bound),'globular'))
            if after_glob:
                if len(words) < 3:
                    continue
                iupred_parts[2][words[0]] = (words[1],words[2])

        with lock:
            out_queue.put(iupred_parts)

def paraBlast(config,process_queue_blast,out_queue,lock,i,err_queue):
    blast_path = config.blast_path
    blast_db_path = config.blast_db_path
    option_number_of_templates = config.option_number_of_templates
    option_seq_thresh = config.option_seq_thresh
    option_ral_thresh = config.option_ral_thresh
    option_res_thresh = config.option_res_thresh
    pdb_path = config.pdb_path
    cwd = os.getcwd()
    with lock:
        process_queue_blast.put(None)
    while True:
        with lock:
            inp = process_queue_blast.get()
        if inp == None:
            return
        try:
            (gene,seq) = inp
            target_name = gene.replace("/","")
            #print  gene,seq
            structures = blast.blast(seq,target_name,blast_path,blast_db_path,nr=option_number_of_templates,seq_thresh=option_seq_thresh,cov_thresh=option_ral_thresh,cwd = "%s/%d" %(cwd,i))
            #print gene,structures
            #print "Blast",len(structures)
            structures = templateSelection.selectTemplates(structures,pdb_path)
            #print "Select",len(structures)
            structures = templateFiltering.filterTemplates(structures,option_seq_thresh,option_res_thresh,option_ral_thresh)
            #print "Filter",len(structures)
            with lock:
                out_queue.put((gene,structures))
        except:
            [e,f,g] = sys.exc_info()
            g = traceback.format_exc()
            with lock:
                err_queue.put((e,f,g,gene))

def autoTemplateSelection(config,db,cursor,manager,lock,proteins,search_tool='MMseqs2'):

    blast_processes = config.blast_processes
    option_seq_thresh = config.option_seq_thresh
    option_res_thresh = config.option_res_thresh
    cwd = os.getcwd()
    pdb_path = config.pdb_path
    errorlog = config.errorlog_path

    mmseqs2_path = config.mmseqs2_path
    mmseqs2_db_path = config.mmseqs2_db_path

    verbose = config.verbose

    if verbose:
        print('Sequence search with: ',search_tool)

    if search_tool == 'Blast': #Legacy

        t0 = time.time()

        process_list_db = set([])
        process_queue_blast = manager.Queue()
        blast_queues = [process_queue_blast]
        n = 0
        gene_error_map = {}

        #seq_map = {}

        #print gene_sequence_map,db,cursor,blast_path,blast_db_path

        for gene in new_genes:
            seq = gene_sequence_map[gene][0]
            if seq == 0 or seq == 1:
                gene_error_map[new_genes[gene]] = seq
            elif seq == "":
                gene_error_map[new_genes[gene]] = 2
            else:
                process_queue_blast.put((gene,seq))
                n += 1
                if n == 1000:
                    process_queue_blast = manager.Queue()
                    blast_queues.append(process_queue_blast)
                    n = 0
                #seq_map[gene] = seq
     
        t1 = time.time()

        #"""paralized blasting of single sequences  
        #print "before parablast"
        t12 = 0.0
        t3 = 0.0
        t2 = 0.0
        t4 = 0.0
        structure_map = {}
        for process_queue_blast in blast_queues:
            t12 += time.time()
            out_queue = manager.Queue()
            err_queue = manager.Queue()
            processes = {}
            for i in range(1,blast_processes + 1):
                try:
                    os.stat("%s/%d" %(cwd,i))
                except:
                    os.mkdir("%s/%d" %(cwd,i))
                p = multiprocessing.Process(target=paraBlast, args=(config,process_queue_blast,out_queue,lock,i,err_queue))
                processes[i] = p
                p.start()
            for i in processes:
                processes[i].join()

            err_queue.put(None)
            while True:
                err = err_queue.get()
                if err == None:
                    break
                (e,f,g,gene) = err
                errortext = "BLAST Error: %s\n%s\n\n" % (gene,'\n'.join([str(e),str(f),str(g)]))
                f = open(errorlog,'a')
                f.write(errortext)
                f.close()
                No_Errors = False

            t2 += time.time()
            #print "after parablast"

            template_map = {}
            out_queue.put(None)
            while True:
                out = out_queue.get()
                if out == None:
                    break
                (gene,structures) = out
                structure_map[gene] = structures
            #"""
            del out_queue
            del process_queue_blast

            t3 += time.time()

        if verbose:
            print("Template Selection Part 1: %s" % (str(t1-t0)))
            print("Template Selection Part 2: %s" % (str(t2-t12)))
            print("Template Selection Part 3: %s" % (str(t3-t2)))

    elif search_tool == 'MMseqs2':
        t0 = time.time()

        mmseqs_tmp_folder = config.mmseqs_tmp_folder
        raw_structure_map,pdb_ids = MMseqs2.search(proteins,mmseqs2_db_path,mmseqs2_path,mmseqs_tmp_folder,option_seq_thresh,verbose=verbose)

        t1 = time.time()

        templateSelection.filterRawStructureMap(raw_structure_map,pdb_ids,pdb_path,option_res_thresh,blast_processes,proteins)

        t2 = time.time()
        if verbose:
            print("Template Selection Part 1: %s" % (str(t1-t0)))
            print("Template Selection Part 2: %s" % (str(t2-t1)))

    return

def paraAlignment(config,db,cursor,manager,lock,proteins):

    No_Errors = True
    alignment_processes = config.alignment_processes
    pdb_path = config.pdb_path
    smiles_path = config.smiles_path
    inchi_path = config.inchi_path
    verbose = config.verbose
    errorlog = config.errorlog_path
    t0 = time.time()
    input_queue = manager.Queue()
    err_queue = manager.Queue()

    in_queues = [input_queue] #partioning the parallized alignment part shall reduce the memory usage, by safing the alignments to the database every 1000 genes.

    n = 0
    for u_ac in proteins.protein_map:
        for (pdb_id,chain) in proteins[u_ac].structure_annotations:
            input_queue.put((u_ac,pdb_id,chain))

        if n == 1000:
            input_queue = manager.Queue()
            in_queues.append(input_queue)
            n = 0
        n += 1

    t1 = time.time()
    if verbose:
        print("Alignment Part 1: %s" % (str(t1-t0)))

    database.getAlignments(proteins,db,cursor,verbose=verbose)

    t2 = time.time()
    if verbose:
        print("Alignment Part 2: %s" % (str(t2-t1)))

    input_queue = manager.Queue()
    out_queue = manager.Queue()

    for u_ac in proteins.protein_map:
        if not proteins[u_ac].stored:
            continue

        all_stored = True
        for pos in proteins[u_ac].positions:
            if not proteins[u_ac].positions[pos].stored:
                all_stored = False
                break
        if all_stored:
            continue

        for u_ac in proteins.protein_map:
            for (pdb_id,chain) in proteins[u_ac].structure_annotations:
                input_queue.put((u_ac,pdb_id,chain))

    processes = {}
    for i in range(1,alignment_processes + 1):
        p = multiprocessing.Process(target=paraMap, args=(config,input_queue,out_queue,lock,proteins))
        processes[i] = p
        p.start()
    for i in processes:
        processes[i].join()

    total_mappings = []
    mutation_updates = []

    out_queue.put(None)
    while True:
        out = out_queue.get()
        if out == None:
            break
        (mutation_updates_part,mappings) = out
        mutation_updates += mutation_updates_part
        total_mappings += mappings

    t3 = time.time()
    if verbose:
        print("Alignment Part 3: %s" % (str(t3-t2)))

    t31 = 0.0
    t4 = 0.0
    t5 = 0.0
    t6 = 0.0
    t7 = 0.0
    t8 = 0.0
    t9 = 0.0
    gene_template_alignment_map = {}
    template_id_map = {}
    alignment_insertion_list = []
    structure_insertion_list = set()

    for input_queue in in_queues:
        t31 += time.time()
        out_queue = manager.Queue()
        error_queue = manager.Queue()
        err_queue = manager.Queue()
        processes = {}
        for i in range(1,alignment_processes + 1):
            p = multiprocessing.Process(target=align, args=(config,input_queue,out_queue,error_queue,lock,err_queue,proteins))
            processes[i] = p
            p.start()
        for i in processes:
            processes[i].join()
            
        err_queue.put(None)
        multiple_errors = set()
        while True:
            err = err_queue.get()
            if err == None:
                break
            (e,f,g,gene,pdb_id,chain) = err
            if (e,gene) in multiple_errors:
                continue
            multiple_errors.add((e,gene))
            errortext = "Alignment Error: %s, %s:%s\n%s\n%s\n%s\n\n" % (gene,pdb_id,chain,'\n'.join([str(e)]),str(f),str(g))
            f = open(errorlog,'a')
            f.write(errortext)
            f.close()
            No_Errors = False

        #print "after alignment"
        t4 += time.time()

        error_map = {}
        error_queue.put(None)
        while True:
            err = error_queue.get()
            if err == None:
                break
            (error,gene,pdb_id,chain) = err
            if not gene in error_map:
                error_map[gene] = {}
                #Only 1 error per gene
                error_map[gene][(pdb_id,chain)] = error

        for gene in error_map:
            for (pdb_id,chain) in error_map[gene]:
                errortext = "Parse error during alignment: %s - %s\n\n" % (gene,str(error_map[gene][(pdb_id,chain)]))
                f = open(errorlog,'a')
                f.write(errortext)
                f.close()

        out_queue.put(None)


        while True:
            out = out_queue.get()
            if out == None:
                break
            (u_ac,pdb_id,chain,sub_infos,alignment_pir,aaclist,update_map,seq_id,coverage,structure) = out
            proteins[u_ac].structure_annotations[(pdb_id,chain)].sequence_identity = seq_id
            proteins[u_ac].structure_annotations[(pdb_id,chain)].coverage = coverage
            proteins.structures[(pdb_id,chain)] = structure
            for old_aac_base in update_map:
                pos = old_aac_base[1:]
                database_pos = pos
                if int(pos) in pos_res_map:
                    database_pos = pos_res_map[int(pos)]
                new_aac_base = '%s%s' % (update_map[old_aac_base][1],pos)
                database_aac_base = '%s%s' % (update_map[old_aac_base][1],database_pos)
                mutation_id = aaclist[new_aac_base]
                mutation_updates.append((mutation_id,database_aac_base))

            proteins[u_ac].structure_annotations[(pdb_id,chain)].sub_infos = sub_infos

            structure_insertion_list.add((pdb_id,chain))
            alignment_insertion_list.append((proteins[u_ac].database_id,pdb_id,chain,alignment_pir))

        del input_queue
        del out_queue
        del error_queue

        t5 += time.time()

    database.updateMutations(mutation_updates,db,cursor)

    t6 += time.time()
    database.insertStructures(structure_insertion_list,db,cursor,smiles_path,inchi_path,pdb_path,proteins)

    t7 += time.time()

    if verbose:
        print("Amount of mappings based on stored structures: ",len(total_mappings))

    database.getStoredResidues(proteins,db,cursor)

    t8 += time.time()
    database.insertAlignments(alignment_insertion_list,proteins,db,cursor)

    t9 += time.time()

    #print "Template amounts, before and after: ",temp_amount,after_amount
    if verbose:
        print("Alignment Part 4: %s" % (str(t4-t31)))
        print("Alignment Part 5: %s" % (str(t5-t4)))
        print("Alignment Part 6: %s" % (str(t6-t5)))
        print("Alignment Part 7: %s" % (str(t7-t6)))
        print("Alignment Part 8: %s" % (str(t8-t7)))
        print("Alignment Part 9: %s" % (str(t9-t8)))

    return No_Errors

def paraMap(config,input_queue,out_queue,lock,proteins):
    pdb_path = config.pdb_path
    with lock:
        input_queue.put(None)
    while True:
        with lock:
            inp = input_queue.get()
        if inp == None:
            return

        (u_ac,pdb_id,chain) = inp
        structure_id = proteins.structures[(pdb_id,chain)].database_id

        template_page = pdb.standardParsePDB(pdb_id,pdb_path,obsolete_check=True)
        if template_page == None:
            continue
        seq_res_map = globalAlignment.createTemplateFasta(template_page,pdb_id,chain,onlySeqResMap = True)

        target_seq,template_seq = proteins[u_ac].structure_annotations[(pdb_id,chain)].alignment

        aaclist = proteins[u_ac].getAACList()

        sub_infos,errors,aaclist,update_map = globalAlignment.getSubPos(target_seq,template_seq,aaclist,seq_res_map)

        #structure of sub_infos: {aacbase:(res_id,template_aa)}

        mutation_updates = []

        for old_aac_base in update_map:
            pos = old_aac_base[1:]
            database_pos = pos
            if int(pos) in pos_res_map:
                database_pos = pos_res_map[int(pos)]
            new_aac_base = '%s%s' % (update_map[old_aac_base][1],pos)
            database_aac_base = '%s%s' % (update_map[old_aac_base][1],database_pos)
            mutation_id = aaclist[new_aac_base]
            mutation_updates.append((mutation_id,database_aac_base))

        mappings = []
        for aacbase in aaclist:
            if not aacbase in sub_infos: #this can happen for given positions > length of the sequence
                continue
            m_id = aaclist[aacbase]
            res_id,t_aa = sub_infos[aacbase]
            if res_id == None: #This happens, when the position is mapped to a gap in the alignment
                continue
            mappings.append((m_id,structure_id,res_id,proteins[u_ac].database_id))

        with lock:
            out_queue.put((mutation_updates,mappings))

    return

def align(config,input_queue,out_queue,error_queue,lock,err_queue,proteins):
    pdb_path = config.pdb_path
    option_seq_thresh = config.option_seq_thresh

    with lock:
        input_queue.put(None)
    while True:
        with lock:
            inp = input_queue.get()
        if inp == None:

            return

        (u_ac,pdb_id,chain) = inp

        try:
            (template_page,error,part1_times,structure) = pdb.getStandardizedPdbFile(pdb_id,chain,proteins.structures[(pdb_id,chain)],pdb_path)
            
            if error == None:
                aaclist = proteins[u_ac].getAACList()
                (coverage,seq_id,sub_infos,alignment_pir,errors,times,aaclist,update_map) = globalAlignment.alignBioPython(u_ac,proteins[u_ac].sequence,pdb_id,template_page,chain,aaclist)

                if sub_infos == None:
                    for err in errors:
                        with lock:
                            error_queue.put((err,gene,pdb_id,chain))
                    continue

                for err in errors:
                    #[e,f,g] = sys.exc_info()
                    #g = traceback.format_exc()
                    with lock:
                        error_queue.put((err,gene,pdb_id,chain))
                #print "after alignment"

                if 100.0*seq_id >= option_seq_thresh:
                    with lock:
                        out_queue.put((u_ac,pdb_id,chain,sub_infos,alignment_pir,aaclist,update_map,seq_id,coverage,structure))
            else:
                with lock:
                    error_queue.put((error,u_ac,pdb_id,chain))
        except:
            [e,f,g] = sys.exc_info()
            g = traceback.format_exc()
            with lock:
                err_queue.put((e,f,g,u_ac,pdb_id,chain))
    

def paraAnnotate(config,db,cursor,manager,lock,No_Errors,proteins):
    annotation_processes = config.annotation_processes
    anno_session_mapping = config.anno_session_mapping
    error_annotations_into_db = config.error_annotations_into_db

    smiles_path = config.smiles_path
    inchi_path = config.inchi_path
    pdb_path = config.pdb_path
    verbose = config.verbose
    errorlog = config.errorlog_path

    t0 = time.time()
    
    input_queue = manager.Queue()

    #new structure for paralell annotation: give each annotation process a pdb and dict of chain and structure information,
    #all chains without structure information shall go into the database as fully annotated structures, which are not aligned (yet)
    #these are unmapped chains, or protein interaction partners, their presence in the database is necesary for the computation of the structural neighborhood
    #a new structure-structure entry has to be created and has to be inserted into the database before the residue insertion
    #homooligomer information is not present for such cases, this information has to be updated, if the chain is mapped at a later iteration or run

    '''
    sys.path.append("/TL/sin/work/agress/RIN")
    import createRINdb
    createRINdb.calculateRINsFromPdbList(pdb_structure_map.keys(),fromScratch=True,forceCentrality=True)
    '''

    size_map = {}
    max_size = 0
    for (pdb_id,chain) in proteins.structures:
        if proteins.structures[(pdb_id,chain)].stored:
            continue
        #print(proteins.structures[(pdb_id,chain)].status())
        s = len(proteins.structures[(pdb_id,chain)].chains)
        if not s in size_map:
            size_map[s] = []
            if s > max_size:
                max_size = s
        size_map[s].append(pdb_id) 

    n_of_structs = 0
    while max_size > 0:
        if max_size in size_map:
            for pdb_id in size_map[max_size]:
                input_queue.put(pdb_id)
                n_of_structs += 1
        max_size -= 1

    if verbose:
        t01 = time.time()
        print("Annotation Part 0.1: %s" % (str(t01-t0)))
    

    total_annotations = {}
    interacting_structure_dict = {}
    complex_profiles = {}

    out_queue = manager.Queue()
    error_queue = manager.Queue()
    err_queue = manager.Queue()
    processes = {}
    if annotation_processes > n_of_structs:
        annotation_processes = n_of_structs
    if verbose:
        print("Going into Annotation with ",annotation_processes,' processes')
    for i in range(1,annotation_processes + 1):
        p = multiprocessing.Process(target=annotate, args=(config,input_queue,out_queue,error_queue,lock,err_queue))
        processes[i] = p
        p.start()
    for i in processes:
        processes[i].join()

    if verbose:
        t02 = time.time()
        print("Annotation Part 0.2: %s" % (str(t02-t01)))

    err_queue.put(None)
    while True:
        err = err_queue.get()
        if err == None:
            break
        (e,f,g,pdb_id) = err
        errortext = "Annotation Error: %s\n%s\n\n" % (pdb_id,'\n'.join([str(e),str(f),str(g)]))
        f = open(errorlog,'a')
        f.write(errortext)
        f.close()
        No_Errors = False

    if verbose:
        t1 = time.time()
        print("Annotation Part 1: %s" % (str(t1-t02)))
    
    with lock:
        out_queue.put(None)

    while True:
        out = out_queue.get()
        if out == None:
            break
        (annotation_chain_dict,pdb_id,interacting_chain_map,residue_residue_dict,ligand_profiles,metal_profiles,ion_profiles,chain_chain_profiles) = out
        for chain in interacting_chain_map:
            interacting_structure_dict[(pdb_id,chain)] = interacting_chain_map[chain]
        
        for chain in annotation_chain_dict:
            annotations = annotation_chain_dict[chain]

            total_annotations[(pdb_id,chain)] = annotations,residue_residue_dict[chain]

        complex_profiles[pdb_id] = ligand_profiles,metal_profiles,ion_profiles,chain_chain_profiles

    if verbose:
        t11 = time.time()
        print('Annotation Part 1.1: %s' % (str(t11-t1)))
    interacting_structure_ids = database.insertInteractingChains(interacting_structure_dict,db,cursor,smiles_path,inchi_path,pdb_path)

    if verbose:
        t12 = time.time()
        print('Annotation Part 1.2: %s' % (str(t12-t11)))
    complex_profile = database.insertComplexes(complex_profiles,db,cursor)

    if verbose:
        t2  = time.time()
        print("Annotation Part 2: %s" % (str(t2-t12)))

    database.insertResidues(total_annotations,db,cursor,interacting_structure_ids,proteins)

    if verbose:
        t21  = time.time()
        print("Annotation Part 2.1: %s" % (str(t21-t2)))

    if verbose:
        t3  = time.time()
        print("Annotation Part 3: %s" % (str(t3-t21)))

    if verbose:
        t4 = time.time()
        print("Annotation Part 4: %s" % (str(t4-t3)))

    database.insertClassifications(db,cursor,proteins,config,complex_profiles)

    if verbose:
        t5 = time.time()
        print("Annotation Part 5: %s" % (str(t5-t4)))

    return No_Errors


def annotate(config,input_queue,out_queue,error_queue,lock,err_queue):
    neighborhood_calculation = config.neighborhood_calculation
    calculate_interaction_profiles = config.calculate_interaction_profiles
    dssp = config.dssp
    dssp_path = config.dssp_path
    pdb_path = config.pdb_path
    rin_db_path = config.rin_db_path

    with lock:
        input_queue.put(None)
    while True:
        inp = input_queue.get()
        if inp == None:
            return
        pdb_id = inp
        try:
            annotation_chain_dict,interacting_chain_map,residue_residue_dict,errorlist,ligand_profiles,metal_profiles,ion_profiles,chain_chain_profiles = templateFiltering.structuralAnalysis(pdb_id,pdb_path,dssp_path,rin_db_path,neighborhood_calculation=neighborhood_calculation,dssp=dssp,calculate_interaction_profiles=calculate_interaction_profiles)
            with lock:
                out_queue.put((annotation_chain_dict,pdb_id,interacting_chain_map,residue_residue_dict,ligand_profiles,metal_profiles,ion_profiles,chain_chain_profiles))
                if len(errorlist) > 0:
                    for (error,e,f,g) in errorlist:
                        err_queue.put((error,f,g,pdb_id))
        except:
            [e,f,g] = sys.exc_info()
            g = traceback.format_exc()
            with lock:
                err_queue.put((e,f,g,pdb_id))

def main(filename,config,output_path,main_file_path):
    n_of_cores = config.proc_n
    species = config.species
    mrna_fasta = config.mrna_fasta
    num_of_cores = config.proc_n
    verbose = config.verbose
    search_tool = config.search_tool
    errorlog = config.errorlog_path
    session = 0 #This can later be used, structman.py could give a specific session id and the pipeline can then expand that session

    background_process_MS = None

    manager = multiprocessing.Manager()
    lock = manager.Lock()

    t0 = time.time()

    if mrna_fasta != None and species == None:
        species = mrna_fasta.split('/')[-1].replace('.fa','').replace('.fasta','')
    if mrna_fasta != None:
        if not os.path.exists(mrna_fasta):
            raise NameError("mRNA path not found: %s" % mrna_fasta)

    #annovar-pipeline in case of vcf-file
    if filename.rsplit(".",1)[1] == "vcf":
        anno_db = "%s_annovar" % db_name.rsplit("_",1)[0]
        print('Convert vcf file format using Annovar')
        if mrna_fasta != None:
            '... and using mrna file: ',mrna_fasta
        nfname = annovar.annovar_pipeline(filename,config.tax_id,config.annovar_path,config.db_adress,config.db_user_name,config.db_password,anno_db,mrna_fasta,ref_id=config.ref_genome_id)
    else:
        nfname = filename

    mrna_fasta_for_annovar = True #make this a option, for the case of mrna fasta files with non-standard protein-ids (may include further debugging)

    if mrna_fasta_for_annovar:
        mrna_fasta = None

    db = MySQLdb.connect(config.db_adress,config.db_user_name,config.db_password,config.db_name)
    cursor = db.cursor()

    t01 = time.time()

    if verbose:
        print("Time for preparation before buildQueue: %s" % (str(t01-t0)))

    junksize = 500

    if verbose:
        print("Call buildQueue with chunksize: %s and file: %s" % (str(junksize),nfname))
    proteins_chunks = buildQueue(config,db,cursor,nfname,junksize,mrna_fasta=mrna_fasta)

    t02 = time.time()
    if verbose:
        print("Time for buildQueue: %s" % (str(t02-t01)))
    
    print("Number of chunks: ",len(proteins_chunks))

    newsession = False
    if session == 0:     
        starttime = SQLDateTime()
        session = database.insertSession(starttime,nfname,db,cursor)
        newsession = True

    date = time.strftime("%a, %d %b %Y %H:%M:%S", time.gmtime())
    errortext  = "###############################################################################\n%s:\n%s - Session: %s\n" % (date,nfname,str(session))

    f = open(errorlog,'a')
    f.write(errortext)
    f.close()

    errors = []
    print(errorlog)
    junk_nr = 1 
    for proteins in proteins_chunks:
        if len(proteins) == 0:
            continue

        #transform the protein map into a Proteins object
        proteins = sdsc.Proteins(proteins)

        print("Chunk %s/%s" % (str(junk_nr),str(len(proteins_chunks))))
        junk_nr+=1
        try:
            os.stat("%s/tmp_structman_pipeline" %(output_path))
        except:
            os.mkdir("%s/tmp_structman_pipeline" %(output_path))  
        os.chdir("%s/tmp_structman_pipeline" %(output_path))
        cwd = "%s/tmp_structman_pipeline" %(output_path)

        try:
            t1 = time.time()
            print("Before protCheck")
            #check for already stored genes and make all the necessary database interactions
            #sets the fields database_id and stored in the protein objects as well as the stored and non stored ids in the proteins object
            database.protCheck(proteins,session,db,cursor)

            t2 = time.time()
            if verbose:
                print("Time for protCheck: %s" % (str(t2-t1)))
            #check for already stored mutations or position twins and make all the necessary database interactions
            #sets the fields database_id and stored in the position objects
            background_process_MS = database.positionCheck(proteins,session,db,cursor,config)

            t3 = time.time()
            if verbose:
                print("Time for positionCheck: %s" % (str(t3-t2)))

            print("Before getSequences")
            background_iu_process = getSequences(proteins,config,manager,lock,db,cursor)

            t4 = time.time()
            if verbose:
                print("Time for getSequences: %s" % (str(t4-t3)))

            print("Before autoTemplateSelection")
            autoTemplateSelection(config,db,cursor,manager,lock,proteins,search_tool=search_tool)

            t5 = time.time()
            if verbose:
                print("Time for Template Selection: %s" % (str(t5-t4)))

            print("Before paraAlignment")
            No_Errors = paraAlignment(config,db,cursor,manager,lock,proteins)

            t6 = time.time()
            if verbose:
                print("Time for Alignment: %s" % (str(t6-t5)))

            if background_iu_process != None:
                background_iu_process.join() #Disorder values have to finished before the classification happens

            print("Before paraAnnotate")
            No_Errors = paraAnnotate(config,db,cursor,manager,lock,No_Errors,proteins)
            t7 = time.time()
            if verbose:
                print("Time for Annotation: %s" % (str(t7-t6)))

            t1 = time.time()
            #join the background inserts
            if background_process_MS != None:
                background_process_MS.join()
            #if background_process_AS != None:
            #    background_process_AS.join()


            t2 = time.time()
            if verbose:
                print('Resttime for background inserts: ',t2-t1)

        #Error-Handling for a whole input line
        except:
            
            [e,f,g] = sys.exc_info()
            g = traceback.format_exc()
            #print "Pipeline Core Error: ",e,f,g
            errortext = '\n'.join([str(e),str(f),str(g)]) + '\n\n'
            f = open(errorlog,'a')
            f.write(errortext)
            f.close()
            No_Errors = False
            if background_process_MS != None:
                background_process_MS.join()

        os.chdir(output_path)
        #"""
        try:
            shutil.rmtree(cwd)
        except:
            pass
        #"""

    if No_Errors:
        errortext  = "Finished without any error\n###############################################################################\n"
        f = open(errorlog,'a')
        f.write(errortext)
        f.close()
    else:
        errortext  = "###############################################################################\n"
        f = open(errorlog,'a')
        f.write(errortext)
        f.close()

        print("At least one error occured, please check the errorlog.")

    if newsession:
        endtime = SQLDateTime()
        database.updateSession(session,endtime,db,cursor)
    db.close()

    tend = time.time()
    print((tend-t0))
    return session
